import json, os
from typing import Dict, Any, List
from PIL import Image
from torch.utils.data import Dataset

class VQAPairs(Dataset):
    """Generic image+question->answer dataset from jsonl generated by make_vqa_pairs.py"""
    def __init__(self, root_dir: str, split: str):
        # expects {root_dir}/{split}.jsonl with fields: image_path, question, answer
        self.items: List[Dict[str, Any]] = []
        path = os.path.join(root_dir, f"{split}.jsonl")
        if not os.path.exists(path):
            raise FileNotFoundError(path)
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line: continue
                self.items.append(json.loads(line))

    def __len__(self) -> int:
        return len(self.items)

    def __getitem__(self, idx: int):
        ex = self.items[idx]
        image = Image.open(ex["image_path"]).convert("RGB")
        return {
            "image": image,
            "question": ex["question"],
            "answer": ex["answer"],
            "image_path": ex["image_path"],
        }
